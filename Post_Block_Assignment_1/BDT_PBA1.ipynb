{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOO/LrXBrdqhf/bBO3XrwFX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Patric-Ramz/bdt-2023-26720051/blob/main/Post_Block_Assignment_1/BDT_PBA1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_PRNpyGRFsH",
        "outputId": "7e3a7a54-1e3c-4a02-c49f-3ffd93a21d30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.2.1\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.4/308.4 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.2/154.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.0/807.0 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.3/671.3 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for timeloop (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.25.2 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 8.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install --quiet apache-beam[interactive]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "users_v = pd.read_csv('/content/drive/My Drive/Datasets/users_v.csv')\n",
        "orders_v = pd.read_csv('/content/drive/My Drive/Datasets/orders_v.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-85fBYPUEX3",
        "outputId": "cefbcfce-ab85-4b80-bb95-2c26c7784588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory for data\n",
        "!mkdir -p data\n",
        "\n",
        "# Download kinglear.txt from Cloud Storage\n",
        "!gsutil cp gs://dataflow-samples/shakespeare/kinglear.txt data/\n",
        "\n",
        "# Display the number of lines in kinglear.txt\n",
        "!wc -l data/kinglear.txt\n",
        "\n",
        "# Display the first three lines of kinglear.txt\n",
        "!head -3 data/kinglear.txt\n",
        "\n",
        "# Import necessary Python packages\n",
        "import apache_beam as beam\n",
        "import re\n",
        "\n",
        "# Set input and output patterns\n",
        "inputs_pattern = 'data/*'\n",
        "outputs_prefix = 'outputs/part'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1zldZHBWS7v",
        "outputId": "b149cbc3-41ab-41b6-8f1b-a9ba4f61a518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://dataflow-samples/shakespeare/kinglear.txt...\n",
            "/ [0 files][    0.0 B/153.6 KiB]                                                \r/ [1 files][153.6 KiB/153.6 KiB]                                                \r\n",
            "Operation completed over 1 objects/153.6 KiB.                                    \n",
            "5525 data/kinglear.txt\n",
            "\tKING LEAR\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "from datetime import datetime\n",
        "\n",
        "def format_user(element):\n",
        "    # Split each line based on comma\n",
        "    fields = element.split(',')\n",
        "\n",
        "    user_id = fields[0]\n",
        "    full_name = fields[1].split()\n",
        "    first_name = full_name[0]\n",
        "    last_name = ' '.join(full_name[1:])\n",
        "\n",
        "    gender = \"Male\" if fields[2] == \"male\" else \"Female\"\n",
        "\n",
        "    # Categorizing the age\n",
        "    age = int(fields[3])\n",
        "    age_category = \"16-55\" if 16 <= age <= 55 else \"56+\"\n",
        "\n",
        "    # Splitting address into City, State and Zip code\n",
        "    address_parts = fields[4].rsplit('-', 2)\n",
        "    city = address_parts[0]\n",
        "    state = address_parts[1]\n",
        "    zip_code = address_parts[2]\n",
        "\n",
        "    # Changing date format\n",
        "    date_format = \"%Y/%m/%d\"\n",
        "    date_joined = datetime.strptime(fields[5], date_format).strftime('%Y-%m-%d')\n",
        "\n",
        "    return f'{user_id}; {first_name} {last_name}; {gender}; {age_category}; {city}, {state}, {zip_code}; {date_joined}'\n",
        "\n",
        "with beam.Pipeline() as p:\n",
        "    (\n",
        "        p | 'Read CSV File' >> beam.io.ReadFromText('/content/drive/My Drive/Datasets/users_v.csv', skip_header_lines=1)\n",
        "          | 'Format Users' >> beam.Map(format_user)\n",
        "          | 'Write to Output CSV' >> beam.io.WriteToText('/content/drive/My Drive/Datasets/marketing_format', header='User Id;Name Surname;Male/Female;16-55;City,state,zip code;YYYY-MM-dd', file_name_suffix='.csv', shard_name_template='')\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "9HvT-ys8WcMZ",
        "outputId": "aa92c168-8331-42b1-d703-e871d2ba993b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 1\n",
        "\n",
        "import apache_beam as beam\n",
        "\n",
        "# Define a function to extract the user_id from users.csv\n",
        "def extract_user_key(element):\n",
        "    fields = element.split(',')\n",
        "    user_id = fields[0]\n",
        "    return (user_id, element)\n",
        "\n",
        "# Define a function to extract the user_id from orders.csv\n",
        "def extract_order_key(element):\n",
        "    fields = element.split(',')\n",
        "    user_id = fields[1]  # Assuming user_id is the second field in orders.csv\n",
        "    return (user_id, element)\n",
        "\n",
        "# Define a function to format the combined output\n",
        "def format_output(element):\n",
        "    user_id, collections = element\n",
        "    user_info = collections['users']\n",
        "    orders = collections['orders']\n",
        "\n",
        "    # Return a combined result for further processing or writing to an output\n",
        "    return (user_id, user_info, orders)\n",
        "\n",
        "with beam.Pipeline() as p:\n",
        "    users = (\n",
        "        p | 'Read Users' >> beam.io.ReadFromText('/content/drive/My Drive/Datasets/users_v.csv', skip_header_lines=1)\n",
        "          | 'Extract User Key' >> beam.Map(extract_user_key)\n",
        "    )\n",
        "\n",
        "    orders = (\n",
        "        p | 'Read Orders' >> beam.io.ReadFromText('/content/drive/My Drive/Datasets/orders_v.csv', skip_header_lines=1)\n",
        "          | 'Extract Order Key' >> beam.Map(extract_order_key)\n",
        "    )\n",
        "\n",
        "    results = (\n",
        "        {'users': users, 'orders': orders}\n",
        "        | 'CoGroupByKey' >> beam.CoGroupByKey()\n",
        "        | 'Format Output' >> beam.Map(format_output)\n",
        "        # You can add additional transforms here, or write to an output\n",
        "    )"
      ],
      "metadata": {
        "id": "AdqvlNbBKskw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 2\n",
        "\n",
        "import apache_beam as beam\n",
        "\n",
        "def extract_gender_and_order(element):\n",
        "    user_id, collections = element\n",
        "    user_info = collections['users'][0]  # Assuming one user record per ID\n",
        "    orders = collections['orders']\n",
        "\n",
        "    # Extract gender from user info\n",
        "    fields = user_info.split(',')\n",
        "    gender = fields[2]  # Assuming gender is the third field in users_v.csv\n",
        "\n",
        "    return (gender, len(orders))\n",
        "\n",
        "def compute_average(element):\n",
        "    gender, order_counts = element\n",
        "    total_orders = sum(order_counts)\n",
        "    number_of_customers = len(order_counts)\n",
        "    average_orders = total_orders / number_of_customers\n",
        "    return (gender, average_orders)\n",
        "\n",
        "with beam.Pipeline() as p:\n",
        "    users = (\n",
        "        p | 'Read Users' >> beam.io.ReadFromText('/content/drive/My Drive/Datasets/users_v.csv', skip_header_lines=1)\n",
        "          | 'Extract User Key' >> beam.Map(extract_user_key)\n",
        "    )\n",
        "\n",
        "    orders = (\n",
        "        p | 'Read Orders' >> beam.io.ReadFromText('/content/drive/My Drive/Datasets/orders_v.csv', skip_header_lines=1)\n",
        "          | 'Extract Order Key' >> beam.Map(extract_order_key)\n",
        "    )\n",
        "\n",
        "    average_orders_by_gender = (\n",
        "        {'users': users, 'orders': orders}\n",
        "        | 'CoGroupByKey' >> beam.CoGroupByKey()\n",
        "        | 'Extract Gender and Order Count' >> beam.Map(extract_gender_and_order)\n",
        "        | 'Group By Gender' >> beam.GroupByKey()\n",
        "        | 'Compute Average by Gender' >> beam.Map(compute_average)\n",
        "        | 'Print Results' >> beam.Map(print)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaENKH8DL1-H",
        "outputId": "62e79275-a5d4-4f79-9acc-c9f34dda6de7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('female', 342.1982608695652)\n",
            "('male', 341.89312344656173)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3\n",
        "\n",
        "import apache_beam as beam\n",
        "from apache_beam import pvalue\n",
        "\n",
        "class SplitOutput(beam.DoFn):\n",
        "    def process(self, element, orders_total):\n",
        "        gender, order_counts = element\n",
        "        total_orders = sum(order_counts)\n",
        "        number_of_customers = len(order_counts)\n",
        "        average_orders = total_orders / number_of_customers\n",
        "\n",
        "        # Update the total number of orders processed\n",
        "        orders_total.inc(total_orders)\n",
        "\n",
        "        return [(gender, average_orders)]\n",
        "\n",
        "with beam.Pipeline() as p:\n",
        "    users = (\n",
        "        p | 'Read Users' >> beam.io.ReadFromText('/content/drive/My Drive/Datasets/users_v.csv', skip_header_lines=1)\n",
        "          | 'Extract User Key for Users' >> beam.Map(extract_user_key)\n",
        "    )\n",
        "\n",
        "    orders = (\n",
        "        p | 'Read Orders' >> beam.io.ReadFromText('/content/drive/My Drive/Datasets/orders_v.csv', skip_header_lines=1)\n",
        "          | 'Extract Order Key for Orders' >> beam.Map(extract_order_key)\n",
        "    )\n",
        "\n",
        "    orders_total = beam.metrics.Metrics.counter('order', 'total')\n",
        "\n",
        "    average_orders_by_gender = (\n",
        "        {'users': users, 'orders': orders}\n",
        "        | 'CoGroupByKey' >> beam.CoGroupByKey()\n",
        "        | 'Extract Gender and Order Count' >> beam.Map(extract_gender_and_order)\n",
        "        | 'Group By Gender' >> beam.GroupByKey()\n",
        "        | 'Compute Average by Gender' >> beam.ParDo(SplitOutput(), orders_total=orders_total)\n",
        "        | 'Print Average Results' >> beam.Map(print)\n",
        "    )\n",
        "\n",
        "    # Printing the total orders after the pipeline finishes\n",
        "    result = p.run()\n",
        "    result.wait_until_finish()\n",
        "metrics = result.metrics().query()\n",
        "for metric in metrics['counters']:\n",
        "    if metric.key.metric.name == 'total':\n",
        "        print(f\"Total number of orders processed: {metric.committed}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYLQfZBqNSEF",
        "outputId": "59668004-0b64-47cd-85cc-a7b75f21104e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('male', 341.89312344656173)\n",
            "('female', 342.1982608695652)\n",
            "('female', 342.1982608695652)\n",
            "('male', 341.89312344656173)\n",
            "Total number of orders processed: 806193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 5\n",
        "\n",
        "import apache_beam as beam\n",
        "\n",
        "# Step 1: Define a function to categorize users into age groups.\n",
        "def categorize_by_age_group(element):\n",
        "    user_id, collections = element\n",
        "    user_info = collections['users'][0]  # Assuming one user record per ID\n",
        "\n",
        "    # Extract age from user info\n",
        "    fields = user_info.split(',')\n",
        "    age = int(fields[3])  # Assuming age is the fourth field in users_v.csv\n",
        "\n",
        "    # Categorize into age groups\n",
        "    if 16 <= age < 26:\n",
        "        age_group = \"16-26\"\n",
        "    elif 26 <= age < 36:\n",
        "        age_group = \"26-36\"\n",
        "    elif 36 <= age < 46:\n",
        "        age_group = \"36-46\"\n",
        "    elif 46 <= age < 56:\n",
        "        age_group = \"46-56\"\n",
        "    else:\n",
        "        age_group = \"Other\"\n",
        "\n",
        "    return (age_group, len(collections['orders']))\n",
        "\n",
        "# Step 2: Read the users and orders datasets.\n",
        "with beam.Pipeline() as p:\n",
        "    users = (\n",
        "        p | 'Read Users' >> beam.io.ReadFromText('/content/drive/My Drive/Datasets/users_v.csv', skip_header_lines=1)\n",
        "          | 'Extract User Key for Users' >> beam.Map(extract_user_key)\n",
        "    )\n",
        "\n",
        "    orders = (\n",
        "        p | 'Read Orders' >> beam.io.ReadFromText('/content/drive/My Drive/Datasets/orders_v.csv', skip_header_lines=1)\n",
        "          | 'Extract Order Key for Orders' >> beam.Map(extract_order_key)\n",
        "    )\n",
        "\n",
        "    # Step 3: Join these datasets based on user_id.\n",
        "    # Step 4: Extract and group by age categories.\n",
        "    age_group_orders = (\n",
        "        {'users': users, 'orders': orders}\n",
        "        | 'CoGroupByKey' >> beam.CoGroupByKey()\n",
        "        | 'Categorize by Age Group' >> beam.Map(categorize_by_age_group)\n",
        "        | 'Count Orders by Age Group' >> beam.CombinePerKey(sum)\n",
        "        | 'Print Results' >> beam.Map(print)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIaybEgITKJT",
        "outputId": "bd83d89d-579d-44c0-a1a2-977db6ef9010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Other', 323193)\n",
            "('26-36', 137232)\n",
            "('16-26', 96019)\n",
            "('36-46', 132048)\n",
            "('46-56', 117701)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 6\n",
        "\n",
        "import apache_beam as beam\n",
        "\n",
        "# Step 1: Filter out orders where spinach was purchased.\n",
        "def filter_spinach_orders(element):\n",
        "    fields = element.split(',')\n",
        "    product_name = fields[2]  # Assuming product name is the third field in orders_v.csv\n",
        "    return product_name.lower() == \"spinach\"\n",
        "\n",
        "# Step 2: Categorize users into age groups and count spinach purchases.\n",
        "def categorize_by_age_group_and_count(element):\n",
        "    user_id, collections = element\n",
        "    user_info = collections['users'][0]  # Assuming one user record per ID\n",
        "\n",
        "    # Extract age from user info\n",
        "    fields = user_info.split(',')\n",
        "    age = int(fields[3])  # Assuming age is the fourth field in users_v.csv\n",
        "\n",
        "    # Categorize into age groups\n",
        "    if 16 <= age < 26:\n",
        "        age_group = \"16-26\"\n",
        "    elif 26 <= age < 36:\n",
        "        age_group = \"26-36\"\n",
        "    elif 36 <= age < 46:\n",
        "        age_group = \"36-46\"\n",
        "    elif 46 <= age < 56:\n",
        "        age_group = \"46-56\"\n",
        "    else:\n",
        "        age_group = \"Other\"\n",
        "\n",
        "    spinach_purchases = len(collections['orders'])\n",
        "\n",
        "    return (age_group, spinach_purchases)\n",
        "\n",
        "with beam.Pipeline() as p:\n",
        "    users = (\n",
        "        p | 'Read Users' >> beam.io.ReadFromText('/content/drive/My Drive/Datasets/users_v.csv', skip_header_lines=1)\n",
        "          | 'Extract User Key for Users' >> beam.Map(extract_user_key)\n",
        "    )\n",
        "\n",
        "    spinach_orders = (\n",
        "        p | 'Read Orders' >> beam.io.ReadFromText('/content/drive/My Drive/Datasets/orders_v.csv', skip_header_lines=1)\n",
        "          | 'Filter Spinach Orders' >> beam.Filter(filter_spinach_orders)\n",
        "          | 'Extract Order Key for Spinach Orders' >> beam.Map(extract_order_key)\n",
        "    )\n",
        "\n",
        "    age_group_spinach_counts = (\n",
        "        {'users': users, 'orders': spinach_orders}\n",
        "        | 'CoGroupByKey' >> beam.CoGroupByKey()\n",
        "        | 'Categorize by Age Group and Count Spinach' >> beam.Map(categorize_by_age_group_and_count)\n",
        "        | 'Count Spinach Purchases by Age Group' >> beam.CombinePerKey(sum)\n",
        "        | 'Print Results' >> beam.Map(print)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8YIV3_dbN2U",
        "outputId": "1a3affc1-a8b3-4a81-e3c9-994920db41bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Other', 1773)\n",
            "('26-36', 724)\n",
            "('16-26', 495)\n",
            "('36-46', 664)\n",
            "('46-56', 586)\n"
          ]
        }
      ]
    }
  ]
}